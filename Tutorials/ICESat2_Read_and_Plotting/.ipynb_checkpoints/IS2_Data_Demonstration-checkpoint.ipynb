{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assured-detroit",
   "metadata": {},
   "source": [
    "# ICESat-2 Data Tutorial\n",
    "---\n",
    "This notebook is designed to give you a first look at ICESat-2 data (the Ice, Cloud, and land Elevation Satellite, 2). There are a range of data products generated from the raw output of the instrument, which fall into categories defined by the processing level:\n",
    "\n",
    "* L0 -- Reconstructed, unprocessed data at full resolution (no sane person would ever look at L0 data)\n",
    "* L1 -- The same reconstructed, unprocessed data, but includes ancillary information (for example, calibration parameters and georeferencing information) and is often calibrated / converted to physical units (instead of instrument voltages, which are often the fundamental measurement).\n",
    "* L2 [The lowest level we would ever look at] -- Derived geophysical parameters at the same resolution as the L1 data\n",
    "* L3 [The most common level to use] -- Data, derived from L2 products, that has been spatially or temporally resampled, and analyzed for additional geophysical properties.\n",
    "\n",
    "For our purposes here, we look at the following heirarchy of products\n",
    "* ATL03 [L2] -- The time, latitude, longitude, and ellipsoidal height for each photon event downlinked from ATLAS.\n",
    "* ATL06 [L3] -- The geolocated estimates of land-ice surface heights and ancillary parameters that can be used to interpret the estimates and assess their quality. Photon events are aggregated into overlapping, along-track segments of a fixed length (40 m) whose centers are 20 meters apart, and the algorithm estimates the along-track slope and height at the center of each segment. \n",
    "* ATL11 [L3] -- The time series of surface heights. It is the lowest-level land-ice product that brings together data from multiple passes over the same points, obviating the need to collect individual ATL06 files for this task.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "To look at the data, I start by importing a series of modules that will be useful for reading and plotting the data. The ICESat-2 read functions come from Tyler Sutterly's github account (a current Postdoc at the University of Washington - https://github.com/tsutterley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "phantom-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sys and glob are useful tools for dealing with the local filesystem.\n",
    "import sys   \n",
    "import glob\n",
    "\n",
    "### numpy and matplotlib are the core analysis packages for manipulating and plotting data arrays\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "\n",
    "### here, we import the local data read utilities from TS\n",
    "sys.path.append('../../Altimetry_Tools/read-ICESat-2/')\n",
    "\n",
    "import icesat2_toolkit.utilities\n",
    "from icesat2_toolkit.read_ICESat2_ATL03 import read_HDF5_ATL03\n",
    "from icesat2_toolkit.read_ICESat2_ATL06 import read_HDF5_ATL06\n",
    "from icesat2_toolkit.read_ICESat2_ATL11 import read_HDF5_ATL11\n",
    "\n",
    "### finally, pyproj is a useful tool for converting geographic coordinates (lat/Lon) to local coordinate systems\n",
    "from pyproj import Transformer\n",
    "\n",
    "### this transformer object is designed to convert latitude/longitude to Antarctic Polarstereographic coordinates.\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3031\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impaired-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In addition, we use something here called a Jupyter \"Magick\" -- this line changes the back-end of how Jupyter treats matplotlib plots.\n",
    "### Instead of producing static images, the matplotlib widget allows you to zoom and pan and interrogate the plot interactively.\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-phoenix",
   "metadata": {},
   "source": [
    "# ATL03\n",
    "---\n",
    "As stated above, ATL03 is the geolocated photon product. Here are a few useful resources for understanding the structure of the files containing ATL03 data.\n",
    "\n",
    "ATL03 Data Dictionary: https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL03_data_dict_v004.pdf\n",
    "\n",
    "ATL03 File Naming Convention: ATL03_[yyyymmdd][hhmmss]\\_[ttttccss]\\_[vvv_rr].h5\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* cc = Cycle\n",
    "* ss = Region\n",
    "* vvv_rr = Version and revision number\n",
    "\n",
    "<br>\n",
    "Here, I start by using `glob` to look in the local file directory for any files with names that start with \"ATL03\", and read in the first file in that list. The output of the read script is a tuple, which contains dictionaries for each file read. Because I want the `data` object to simply be a dictionary, I immediately select just the first entry in the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "applicable-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'ancillary_data', 'atlas_impulse_response'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = glob.glob('ATL03*')\n",
    "data_03 = read_HDF5_ATL03(fn[0])[0]\n",
    "data_03.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-talent",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Exploring dictionaries often involves a lot of the `.keys` method -- remember, dictionaries store data as \"key/value pairs\", so if you want to see the different storage fields, those are listed as the `keys`. The data dictionary linked above provides text-definitions of each of the keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ideal-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['delta_time', 'dist_ph_across', 'dist_ph_along', 'h_ph', 'lat_ph', 'lon_ph', 'pce_mframe_cnt', 'ph_id_channel', 'ph_id_count', 'ph_id_pulse', 'quality_ph', 'signal_conf_ph'])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_03['gt1l']['heights'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "north-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_cnt = np.array(data_03['gt1l']['geolocation']['segment_ph_cnt'])\n",
    "seg_cnt = np.concatenate([np.atleast_1d(0),seg_cnt])\n",
    "seg_cnt = np.cumsum(seg_cnt)\n",
    "\n",
    "\n",
    "ref_index = np.zeros(data_03['gt1l']['heights']['signal_conf_ph'][:,4].shape,dtype=np.int32)\n",
    "for i,ind_ref in enumerate(seg_cnt[:-1]):\n",
    "    #print(i)\n",
    "    ref_index[ind_ref:seg_cnt[i+1]] = i    \n",
    "\n",
    "    \n",
    "ph_x = data_03['gt1l']['heights']['dist_ph_along']+data_03['gt1l']['geolocation']['segment_dist_x'][ref_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-poker",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Let's take a look at the photons, plotted in terms of their confidence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "equipped-omaha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ff2d2ad60646469d01e5f000621178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Distance Along Track (m)')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Here we define the limits to good data\n",
    "start_xatc = 28500000\n",
    "\n",
    "color_inds = np.uint16(np.linspace(0,256,6))\n",
    "sizes = [0.1,0.2,0.4,0.9,1.5]\n",
    "sizes = [1,1,1,1,1]\n",
    "confs = [0,1,2,4]\n",
    "\n",
    "############ And then we plot!\n",
    "plt.figure()\n",
    "\n",
    "for i, conf_vals in enumerate(confs):\n",
    "    keep_inds = np.where(np.all([[data_03['gt1l']['heights']['signal_conf_ph'][:,4] == conf_vals],[ph_x > 300000+start_xatc],[ph_x < 400000+start_xatc]],axis=0)[0])\n",
    "    plt.plot(ph_x[keep_inds],data_03['gt1l']['heights']['h_ph'][keep_inds],'.',ms=sizes[i],color=cmocean.cm.ice_r(color_inds[i]))\n",
    "\n",
    "plt.ylabel('Elevation (m)')\n",
    "plt.xlabel('Distance Along Track (m)')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-guatemala",
   "metadata": {},
   "source": [
    "# ATL06\n",
    "---\n",
    "ATL06 uses a surface finding algorithm to determine the position and slope of the ice sheet surface.\n",
    "\n",
    "ATL06 Data Dictionary: https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL06_data_dict_v004.pdf\n",
    "\n",
    "ATL06 File Naming Convention: ATL06_[yyyymmdd][hhmmss]\\_[ttttccss]\\_[vvv_rr].h5\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* cc = Cycle\n",
    "* ss = Region\n",
    "* vvv_rr = Version and revision number\n",
    "\n",
    "<br><br>\n",
    "As before, we read in the first file with a name starting \"ATL06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "elder-taxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment', 'ancillary_data'])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = glob.glob('ATL06*')\n",
    "data_06 = read_HDF5_ATL06(fn[0])[0]\n",
    "data_06.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "minimal-justice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['land_ice_segments'])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_06['gt1l'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "unauthorized-veteran",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bias_correction', 'dem', 'fit_statistics', 'geophysical', 'ground_track', 'atl06_quality_summary', 'delta_time', 'h_li', 'h_li_sigma', 'latitude', 'longitude', 'segment_id', 'sigma_geo_h'])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_06['gt1l']['land_ice_segments'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ambient-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ref_azimuth', 'ref_coelv', 'seg_azimuth', 'sigma_geo_at', 'sigma_geo_r', 'sigma_geo_xt', 'x_atc', 'y_atc'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_06['gt1l']['land_ice_segments']['ground_track'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-decimal",
   "metadata": {},
   "source": [
    "<br><br> \n",
    "Here, we can plot the fit segments on top of the ATL03 data, to demonstrate exactly where ATL06 comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "passing-restoration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f2599a9064499c926c00c0358ea3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Distance Along Track (m)')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Here we regenerate the ATL03 plot\n",
    "plt.figure()\n",
    "\n",
    "color_inds = np.uint16(np.linspace(0,256,6))\n",
    "sizes = [0.1,0.2,0.4,0.9,1.5]\n",
    "sizes = [1,1,1,1,1]\n",
    "confs = [0,1,2,4]\n",
    "for i, conf_vals in enumerate(confs):\n",
    "    keep_inds = np.where(np.all([[data_03['gt1l']['heights']['signal_conf_ph'][:,4] == conf_vals],[ph_x > 300000+start_xatc],[ph_x < 400000+start_xatc]],axis=0)[0])\n",
    "    plt.plot(ph_x[keep_inds]-start_xatc,data_03['gt1l']['heights']['h_ph'][keep_inds],'.',ms=sizes[i],color=cmocean.cm.ice_r(color_inds[i]))\n",
    "\n",
    "\n",
    "############ Here we define the limits to good data\n",
    "start_xatc = data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'][0]\n",
    "keep_inds = np.where(np.all([[data_06['gt1l']['land_ice_segments']['atl06_quality_summary'] == 0],[data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'] > 300000+start_xatc],[data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'] < 400000+start_xatc]],axis=0)[0])\n",
    "\n",
    "############ Here we build up the segment coordinates\n",
    "at_x = np.squeeze(data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'][keep_inds]-start_xatc)\n",
    "\n",
    "at_x1 = at_x - 20;\n",
    "at_x2 = at_x + 20;\n",
    "at_y1 = data_06['gt1l']['land_ice_segments']['h_li'][keep_inds] - 20*data_06['gt1l']['land_ice_segments']['fit_statistics']['dh_fit_dx'][keep_inds]\n",
    "at_y2 = data_06['gt1l']['land_ice_segments']['h_li'][keep_inds] + 20*data_06['gt1l']['land_ice_segments']['fit_statistics']['dh_fit_dx'][keep_inds]\n",
    "\n",
    "############ We assemble the multidimensional array\n",
    "at_x_final = np.array([[at_x1],[at_x2]]).squeeze()\n",
    "at_y_final = np.array([[at_y1],[at_y2]]).squeeze()\n",
    "\n",
    "plt.plot(at_x_final,at_y_final,color='black')\n",
    "\n",
    "plt.ylabel('Elevation (m)')\n",
    "plt.xlabel('Distance Along Track (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "distributed-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb208b802040438686498946c1cb9701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beams = ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']\n",
    "\n",
    "plt.figure()\n",
    "for i,beam_opts in enumerate(beams):\n",
    "    x,y = transformer.transform(data[beam_opts]['land_ice_segments']['latitude'],data[beam_opts]['land_ice_segments']['longitude'])\n",
    "    plt.plot(x[keep_inds],y[keep_inds],'.',ms=1,color='black')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-amateur",
   "metadata": {},
   "source": [
    "# ATL11\n",
    "---\n",
    "ATL11 uses repeat observations of ATL06 to determine the height change through time. This uses each beam pair to determine the cross-track slope, to correct for height changes that are not due to changes in the glacier system but instead due to imprecision in the ground-track position.\n",
    "\n",
    "ATL11 Data Dictionary: https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL11_data_dict_v003.pdf\n",
    "\n",
    "ATL11 File Naming Convention: ATL11_[tttt][ss]\\_[cccc]\\_[vvv_rr].h5\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* ss = Region\n",
    "* cccc = First and last cycles of data included in the file\n",
    "* vvv_rr = Version and revision number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "leading-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pt1', 'pt2', 'pt3', 'orbit_info', 'quality_assessment', 'ancillary_data'])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = glob.glob('ATL11*')\n",
    "data11 = read_HDF5_ATL11(fn[0])[0]\n",
    "data11.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "national-citation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cycle_number', 'delta_time', 'h_corr', 'h_corr_sigma', 'h_corr_sigma_systematic', 'latitude', 'longitude', 'quality_summary', 'ref_pt', 'cycle_stats'])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11['pt1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "quarterly-producer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.4028235e+38,  3.4028235e+38,  3.4028235e+38,  3.4028235e+38,\n",
       "       -2.8647327e+01,  3.4028235e+38, -2.8306925e+01], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11['pt1']['h_corr'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "underlying-rwanda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e4cf27859643b99ec4444497aba006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f39e4c2e3a0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "color_inds = np.uint16(np.linspace(0,256,10))\n",
    "\n",
    "for i,cycles in enumerate(data11['pt1']['cycle_number']):\n",
    "    keep_inds = np.where(np.all([[data11['pt1']['quality_summary'][:,i] == 0],[data11['pt1']['h_corr'][:,i] < 1e4]],axis=0)[0])\n",
    "    plt.plot(data11['pt1']['ref_pt'][keep_inds],np.squeeze(data11['pt1']['h_corr'][keep_inds,i]),'.',color=cmocean.cm.ice_r(color_inds[i]),label='Cycle '+str(cycles))\n",
    "    \n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
